<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CLOVA">
  <meta name="keywords" content="CLOVA">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <style>
    .center {
    display: block;
        margin: auto;
    }
    </style>

  <style>
    .video-container {
        display: flex;
        justify-content: space-between;
        margin: 20px 0;
    }

    .video-container iframe {
        max-width: 90%; /* 调整iframe的宽度，以适应屏幕 */
        box-sizing: border-box;
    }
</style>
  <title>CLOVA</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">CLOVA: A Closed-LOop Visual Assistant with Tool Usage and Update</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zhigao2017.github.io/">Zhi Gao</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://yuntaodu.github.io/">Yuntao Du</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/ZhXTong">Xintong Zhang</a><sup>3,2</sup>,</span>
            <span class="author-block">
              <a href="https://jeasinema.github.io/">Xiaojian Ma</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/cocacola-lab">Wenjuan Han</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a><sup>1,2,4</sup>,</span>
            <span class="author-block">
              <a href="https://liqing-ustc.github.io/">Qing Li</a><sup>2</sup></span>                                                                                  
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Peking University</span>
            <span class="author-block"><sup>2</sup>Beijing Institute for General Artificial Intelligence (BIGAI)</span>
            <span class="author-block"><sup>3</sup>Beijing Jiaotong University</span>
            <span class="author-block"><sup>4</sup>Tsinghua University</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
            </div>
          </div>


          <br>
          <img width="100%" src="file/illustration_examples3.png">
          <br>
          <figcaption style="font-size: 18px;font-family: 'Times New Roman', Times, serif;">Figure 1. Several examples of CLOVA</figcaption>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" >
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Leveraging large language models (LLMs) to integrate off-the-shelf tools (e.g., visual models and image processing functions) is a promising research direction to build powerful visual assistants for solving diverse visual tasks. However, the learning capability is rarely explored in existing methods, as they freeze the used tools after deployment, thereby limiting the generalization to new environments requiring specific knowledge. In this paper, we propose CLOVA, a Closed-Loop Visual Assistant to address this limitation, which encompasses inference, reflection, and learning phases in a closed-loop framework. During inference, LLMs generate programs and execute corresponding tools to accomplish given tasks. The reflection phase introduces a multimodal global-local reflection scheme to analyze whether and which tool needs to be updated based on environmental feedback. Lastly, the learning phase uses three flexible manners to collect training data in real-time and introduces a novel prompt tuning scheme to update the tools, enabling CLOVA to efficiently learn new knowledge without human involvement. Experimental results show that CLOVA outperforms tool-usage methods by 5\% in visual question answering and multiple-image reasoning tasks, by 10\% in knowledge tagging tasks, and by 20\% in image editing tasks, highlighting significance of the learning capability for general visual assistants.
          </p>

    </div>

    <h2 class="subtitle has-text-justified">
      <b>TL;DR:</b> We propose CLOVA, a general visual assistant that updates both LLMs and visual models via inference, reflection, and learning in a closed-
      loop framework. 
    </h2>
    <img width="95%" src="file/illustration_examples_framework.png">
    <br>
    <figcaption style="font-size: 18px;font-family: 'Times New Roman', Times, serif;" align="left">Figure 2. Framework of CLOVA. CLOVA is a general visual assistant that updates both LLMs and visual models via inference, reflection, and learning in a closed-loop framework. During inference, CLOVA uses LLMs to integrate visual tools to accomplish given tasks. In reflection, CLOVA identifies models that require updating based on environmental feedback. Finally, in learning, CLOVA collects data and updates models accordingly. </figcaption>
</section>



<section class="section" >
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            CLOVA has three phases: inference, reflection, and learning, as shown Figure 2. In the inference phase, CLOVA uses LLMs to generate programs and executes corresponding tools to solve the task. The reflection phase introduces a multimodal global-local reflection scheme that uses LLMs to generate critiques, identifying which tool needs to be updated. During learning, we employ three manners to collect training data and use a training-validation prompt tuning scheme to update the tools. 
          </p>

    </div>

    <h2 class="subtitle has-text-justified"></h2>
      <b>Inference</b> 
      <div class="content has-text-justified">
      <p>
      Our inference phase is based on VISPROG, while the difference is that CLOVA first uses LLMs to generate plans and then generates programs based on the plans, instead of directly generating programs.
      Plans can be seen as intermediate reasoning chains that benefit the inference and reflection phases. 
      Given a task, CLOVA selects in-context examples from a demonstration pool, including correct examples and incorrect examples with error critiques.
      These examples are used to create prompts that are then sent to LLMs for plan and program generation.
      Finally, the program is parsed to execute visual tools.
    </p>
    </div>
    <br>
    <img width="65%" src="file/framework_inference.png" class="center">
    <figcaption style="font-size: 18px;font-family: 'Times New Roman', Times, serif;" align="center">Figure 3. Illustration of the inference phase in CLOVA. </figcaption>



    <h2 class="subtitle has-text-justified"></h2>
      <b>Reflection</b> 
      <div class="content has-text-justified">
      <p>
        In the inference phase, if a task is not solved correctly, the multimodal global-local reflection scheme uses LLMs to generate critiques, identifying which tool needs to be updated.
        We convert visual results into textual form. Then, CLOVA uses global reflection to generate critiques in a one-go manner.
        If CLOVA still fails after the tools are updated via global reflection and the learning phase --meaning the actual tools that lead to the faulty response are still to be found, we resort to local reflection to analyze each step of the program.
    </p>
  </div>
    <br>
    <img width="65%" src="file/framework_reflection.png" class="center">
    <figcaption style="font-size: 18px;font-family: 'Times New Roman', Times, serif;" align="center">Figure 4. Illustration of the reflection phase in CLOVA. </figcaption>





    <h2 class="subtitle has-text-justified"></h2>
      <b>Learning</b> 
      <div class="content has-text-justified">
      <p>
        After obtaining tools that need to be updated from the reflection phase, CLOVA then moves to the learning phase to collect training data and goes through training-validation prompt tuning to update them.
        Since the tools that need to be updated can be rather different, we explore three manners to collect data in real-time.
        Given the collected data, we invoke training-validation prompt tuning to update tools.
        During inference, we use prompt ensemble to retrieve and utilize prompts from a aforementioned prompt pool.
    </p>
  </div>
    <br>
    <img width="65%" src="file/framework_learning.png" class="center">
    <figcaption style="font-size: 18px;font-family: 'Times New Roman', Times, serif;" align="center">Figure 5. Illustration of the learning phase in CLOVA. </figcaption>


  </section>


<section class="section" >
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Video Demo</h2>
        <div class="content has-text-justified">
    </div>
    <div class="container is-max-desktop">
      <div class="hero-body">
        <iframe width="900" height="510"
           src="file/demo_all_12.12_4.mp4">
        </iframe>
      </div>
    </div>



  </div>

</section>

</body>
</html>
